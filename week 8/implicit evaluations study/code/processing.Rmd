---
title: "Evaluations of positive and negative stimuli using the Affective Misattribution Procedure (AMP) and self-reports"
subtitle: "Data processing"
author: "Template: Ian Hussey; content: [Student name]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

# Dependencies

```{r}

library(tidyverse)
library(janitor) # for clean_names()
library(stringr)

```

# Get data

```{r}

# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
  janitor::clean_names()

# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()

# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
  janitor::clean_names()

# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
  janitor::clean_names()

```

# Demographics

```{r}

dat_age_gender <- data_demographics_raw |>
  select(subject, date, time, trialcode, response) |>
  pivot_wider(names_from = trialcode,
              values_from = response) |>
  mutate(gender = tolower(gender),
         gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
         gender = case_when(gender == "female" ~ gender,
                            gender == "male" ~ gender,
                            gender == "nonbinary" ~ gender,
                            gender == "woman" ~ "female",
                            gender == "man" ~ "male",
                            TRUE ~ "other/missing/error"),
         age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it. 
                         TRUE ~ "other/missing/error")) 

```

# Exclusions / data quality

## AMP

```{r}

data_amp_performance_criteria <- data_amp_raw |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |> 
  group_by(subject) |> 
  summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
  mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))

# determine modal number of trials
data_amp_completeness <- data_amp_raw |>
  filter(blockcode != "practice",
         trialcode != "instructions") |>
  group_by(subject) |>
  count() |>
  ungroup() |>
  mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) |>
  select(-n)

# data_amp_completeness |>
#   count(n)

```

- One participant with 8 trials appears to be a partial completion (check raw data?)
- One participant with 144 trials appears to be a repeat participant. I've chosen to exclude them entirely, but you could also have a more elaborate strategy where you retain only their first completion.

# Self-reports

```{r}

# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
  select(subject, trialcode, response) |>
  filter(trialcode %in% c("like", "prefer", "positive")) |>
  rename(item = trialcode) |>
  filter(response != "Ctrl+'B'") |>
  mutate(response = as.numeric(response))

# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
  group_by(subject) |>
  summarize(mean_evaluation = mean(response, na.rm = TRUE))

# combined
data_selfreport_scored <- 
  full_join(data_selfreport_trial_level |>
              pivot_wider(names_from = "item",
                          values_from = "response"),
            data_selfreport_mean_score,
            by = "subject")

```

# Affect Misattribution Procedure

TODO extract evaluations on the AMP test blocks and convert to an overall bias score

```{r}
data_amp_score_before_check<-data_amp_raw|>
  filter(blockcode != "practice",
         trialcode != "instructions")|>
  select(subject, evaluation=correct, trialcode)|>
  mutate(primecongruent= case_when(trialcode == "prime_negative"&evaluation==0~ "congruent",
                                   trialcode == "prime_positive"&evaluation==1~ "congruent",
                                   TRUE~"incongruent"))

#start CHECK1: check in a table if the two values (from the column "evaluation" and "trialcode") have been converted correctly into congruent or incongruent) 
#important--> frequency should be 0 for the cases:
###.  1,	prime_negative,	congrent	
###.  0,	prime_positive,	congrent
###.  1,	prime_negative,	incongruent	
###.  0,	prime_positive,	incongruent
check1<- data_amp_score_before_check|>
  select(-subject)
table_check1<-table(check1)
table_check1

#Another way of visualization (Check1)
anotherway_check1 <- as.data.frame(table_check1)
colnames(anotherway_check1) <- c("evaluation", "trialcode","Primecongruent" ,"Frequency")
anotherway_check1

#Another way of visualization (Check1)
check1<-data_amp_score_before_check|>
  mutate(check=case_when(evaluation=="1" & trialcode=="prime_negative" & primecongruent=="congruent"~ "Warning",
                         evaluation=="0" & trialcode=="prime_positive" & primecongruent=="congruent"~ "Warning",
                         evaluation=="0" & trialcode=="prime_negative" & primecongruent=="incongruent"~ "Warning",
                         evaluation=="1" & trialcode=="prime_positive" & primecongruent=="incongruent"~ "Warning",
                         TRUE~ "Correct"))
check1|>count(check)
#end CHECK1

#start CHECK2: Is the sum of congruent (2_2) and incongruent (check2_3) equal to the total number of trails (check2_1)?
check2_1<-data_amp_raw|>
  filter(blockcode != "practice",
         trialcode != "instructions")|>
  count(subject)|>
  rename(total_number_trails=n)

check2_2<-data_amp_score_before_check|>
  filter(primecongruent=="congruent")|>
  group_by(subject)|>
  count(primecongruent)|>
  summarise(number_congruent=sum(n))

check2_3<-data_amp_score_before_check|>
  filter(primecongruent=="incongruent")|>
  group_by(subject)|>
  count(primecongruent)|>
  summarise(number_incongruent=sum(n))

check2<-check2_1|>
  full_join(check2_2, by ="subject")|>
  full_join(check2_3, by ="subject")|>
  mutate(check=case_when(number_congruent+number_incongruent== total_number_trails~ "Correct",
                         number_congruent== total_number_trails& is.na(number_incongruent) ~ "Correct",
                         is.na(number_congruent) & number_incongruent== total_number_trails ~ "Correct",
                         TRUE ~ "Warning"))
check2|>count(check)
#end CHECK2

data_amp_score<-data_amp_score_before_check|> group_by(subject) |>
  summarise(evaluation_score = sum(primecongruent=="congruent")/(sum(primecongruent=="congruent")+sum(primecongruent=="incongruent")))

#start CHECK3 and CHECK4: are the values between 0 (check3) and 1 (check4):
check2and3 <- data_amp_score|>
  mutate(check=if_else(evaluation_score<1 & evaluation_score>=0,"correct", "Warning"))
check2and3|>count(check)
#end CHECK3 and CHECK4

#Start CHECK5: Select 1 random subject and check the value manually and step by step
#select a random subject
random_row <- data_amp_score_before_check|> sample_n(1)
random_subject<- random_row$subject

#check5_1: here, you have an overview about the values from your random subject
check5_1<- data_amp_score_before_check|>
  filter(subject==random_subject)|>
  arrange(primecongruent)
check5_1 

# check5_2: verify if the column "Primecongruent" has been filled correctly. 
check5_2<-check5_1|>
  select(-subject)
table_check5_2<-table(check5_2)
table_check5_2

#Check5_3: Verify if the values have been calculated correctly
check5_3<-check5_1 |>count(primecongruent)
check5_3$Proportion <- as.numeric(check5_3$n) /sum(check5_3$n)
proportion_5_3  <- subset(check5_3$n, check5_3$primecongruent == "congruent")/sum(check5_3$n)
proportion_to_check<-subset(data_amp_score$evaluation_score,data_amp_score$subject== random_subject )
message <- ifelse(proportion_5_3== proportion_to_check, "Perfect, the variables match.", "Warning, the variables do not match.")
cat(message)
print(c(proportion_5_3,proportion_to_check))
#End CHECK5
```

# Combine

```{r}

# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
  full_join(data_selfreport_scored, by = "subject") |> 
  full_join(data_amp_performance_criteria, by = "subject") |>
  full_join(data_amp_completeness, by = "subject")|>
  full_join(data_amp_score, by = "subject")

# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained. 
data_processed_duplicates <- data_processed_temp |>
  count(subject) |>
  mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
  select(-n)

# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
  full_join(data_processed_duplicates, by = "subject")

```

#Master exclude variable Self-Report

```{r}
data_processed_before_exclusions <- data_processed_before_exclusions|>
  mutate(exclude_selfreport = case_when(is.na(like) ~ "exclude",
                                        is.na(prefer) ~ "exclude",
                                        is.na(positive) ~ "exclude",
                                        TRUE ~ "include"))

```

# Define master exclusions

```{r}

# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
  mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
                                         tolower(gender) == "test" ~ "exclude",
                                         is.na(mean_evaluation) ~ "exclude",
                                         # in this case we will exclude participants with missing demographics data or outcomes measures data. 
                                         # Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random. 
                                         # How to treat missing data is a  whole area of work in itself, which we wont cover here.
                                         is.na(age) ~ "exclude", 
                                         is.na(gender) ~ "exclude",
                                         exclude_amp_performance == "exclude" ~ "exclude",
                                         exclude_duplicate_data == "exclude" ~ "exclude",
                                         exclude_amp_completeness == "exclude" ~ "exclude",
                                         exclude_selfreport== "exclude" ~ "exclude",
                                         TRUE ~ "include"))

```

# Write to disk

```{r}

# in case this dir doesn't exist, create it
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")

```

# Session info

```{r}

sessionInfo()

```


